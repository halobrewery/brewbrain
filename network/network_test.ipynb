{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from recipedataset import RecipeDataset, RECIPE_DATASET_FILENAME, NUM_GRAIN_SLOTS, NUM_ADJUNCT_SLOTS, NUM_HOP_SLOTS, NUM_MISC_SLOTS, NUM_MICROORGANISM_SLOTS, NUM_FERMENT_STAGE_SLOTS, NUM_MASH_STEPS\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def layer_init_ortho(layer, std=np.sqrt(2)):\n",
    "  nn.init.orthogonal_(layer.weight, std)\n",
    "  nn.init.constant_(layer.bias, 0.0)\n",
    "  return layer\n",
    "\n",
    "def layer_init_xavier(layer, gain):\n",
    "  nn.init.xavier_normal_(layer.weight, gain)\n",
    "  nn.init.constant_(layer.bias, 0.0)\n",
    "  return layer\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "  std = torch.exp(0.5 * logvar)\n",
    "  eps = torch.randn_like(std)\n",
    "  return eps * std + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "# Load the dataset and create a dataloader for it\n",
    "with open(\"../\" + RECIPE_DATASET_FILENAME, 'rb') as f:\n",
    "  dataset = pickle.load(f)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(dataloader):\n",
    "  if batch_idx == 1:\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5899"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAIN_TYPE_EMBED_SIZE         = 32\n",
    "ADJUNCT_TYPE_EMBED_SIZE       = 32\n",
    "HOP_TYPE_EMBED_SIZE           = 96\n",
    "MISC_TYPE_EMBED_SIZE          = 64\n",
    "MICROORGANISM_TYPE_EMBED_SIZE = 64\n",
    "\n",
    "class RecipeNetArgs:\n",
    "  def __init__(self, dataset) -> None:\n",
    "    # Recipe-specific constraints ***\n",
    "    self.num_mash_steps          = NUM_MASH_STEPS\n",
    "    self.num_grain_slots         = NUM_GRAIN_SLOTS\n",
    "    self.num_adjunct_slots       = NUM_ADJUNCT_SLOTS\n",
    "    self.num_hop_slots           = NUM_HOP_SLOTS\n",
    "    self.num_misc_slots          = NUM_MISC_SLOTS\n",
    "    self.num_microorganism_slots = NUM_MICROORGANISM_SLOTS\n",
    "    self.num_ferment_stage_slots = NUM_FERMENT_STAGE_SLOTS\n",
    "    \n",
    "    # NOTE: All types include a \"None\" (i.e., empty) category\n",
    "    self.num_grain_types         = len(dataset.core_grains_idx_to_dbid) # Number of (core) grain types (rows in the DB)\n",
    "    self.num_adjunct_types       = len(dataset.core_adjs_idx_to_dbid)   # Number of (core) adjunct types (rows in the DB)\n",
    "    self.num_hop_types           = len(dataset.hops_idx_to_dbid)        # Number of hop types (rows in the DB)\n",
    "    self.num_misc_types          = len(dataset.miscs_idx_to_dbid)       # Number of misc. types (rows in the DB)\n",
    "    self.num_microorganism_types = len(dataset.mos_idx_to_dbid)         # Number of microrganism types (rows in the DB)\n",
    "    \n",
    "    self.num_mash_step_types  = len(dataset.mash_step_idx_to_name)  # Number of mash step types (e.g., Infusion, Decoction, Temperature)\n",
    "    self.num_hop_stage_types  = len(dataset.hop_stage_idx_to_name)  # Number of hop stage types (e.g., Mash, Boil, Primary, ...)\n",
    "    self.num_misc_stage_types = len(dataset.misc_stage_idx_to_name) # Number of misc stage types (e.g., Mash, Boil, Primary, ...)\n",
    "    self.num_mo_stage_types   = len(dataset.mo_stage_idx_to_name)   # Number of microorganism stage types (e.g., Primary, Secondary)\n",
    "    \n",
    "    # Embedding sizes ***\n",
    "    self.grain_type_embed_size         = GRAIN_TYPE_EMBED_SIZE\n",
    "    self.adjunct_type_embed_size       = ADJUNCT_TYPE_EMBED_SIZE\n",
    "    self.hop_type_embed_size           = HOP_TYPE_EMBED_SIZE\n",
    "    self.misc_type_embed_size          = MISC_TYPE_EMBED_SIZE\n",
    "    self.microorganism_type_embed_size = MICROORGANISM_TYPE_EMBED_SIZE\n",
    "    \n",
    "    # Network-specific hyperparameters/constraints ***\n",
    "    self.num_hidden_layers = 1\n",
    "    self.hidden_size = 1024\n",
    "    self.z_size = 64 # Latent-bottleneck dimension\n",
    "    self.activation_fn = nn.ELU\n",
    "    self.gain = nn.init.calculate_gain('linear', None) # Make sure this corresponds to the activation function!\n",
    "    self.num_inputs = self.calc_num_inputs()\n",
    "  \n",
    "  def calc_num_inputs(self):\n",
    "    \"\"\"Determine the number of inputs to the network.\n",
    "    Returns:\n",
    "        int: The total number of network inputs.\n",
    "    \"\"\"\n",
    "    # (boil_time + mash_ph + sparge_temp)\n",
    "    num_simple_inputs = 3 \n",
    "    # Mash steps (step_type_index_size + step_time + step_temp) * (number of slots) - ordering assumed [0: step 1, 1: step 2, etc.]\n",
    "    num_mash_step_inputs = self.num_mash_steps*(self.num_mash_step_types + 2)\n",
    "    # Fermentation stages (step_time + step_temp) * (number of stages) - ordering assumed [0: primary, 1: secondary]\n",
    "    num_ferment_step_inputs = self.num_ferment_stage_slots*(2)\n",
    "    # Grain/Malt bill slots (grain_type_embed_size + amount) * (number of slots) - no ordering\n",
    "    num_grain_slot_inputs = self.num_grain_slots*(self.grain_type_embed_size + 1)\n",
    "    # Adjunct slots (adjunct_type_embed_size + amount) * (number of slots) - no ordering\n",
    "    num_adjunct_slot_inputs = self.num_adjunct_slots*(self.adjunct_type_embed_size + 1)\n",
    "    # Hop slots (hop_type_embed_size + stage_type_index_size + time + concentration) * (number of slots) - no ordering\n",
    "    num_hop_slot_inputs = self.num_hop_slots*(self.hop_type_embed_size + self.num_hop_stage_types + 2)\n",
    "    # Misc. slots (misc_type_embed_size + stage_type_index_size + time + amounts) * (number of slots) - no ordering\n",
    "    num_misc_slot_inputs = self.num_misc_slots*(self.misc_type_embed_size + self.num_misc_stage_types + 2)\n",
    "    # Microorganism slots (mo_type_embed_size + stage_type_index_size) * (number of slots) - no ordering\n",
    "    num_mo_slot_inputs = self.num_microorganism_slots*(self.microorganism_type_embed_size + self.num_mo_stage_types)\n",
    "\n",
    "    return num_simple_inputs + num_mash_step_inputs + num_ferment_step_inputs + num_grain_slot_inputs + \\\n",
    "      num_adjunct_slot_inputs + num_hop_slot_inputs + num_misc_slot_inputs + num_mo_slot_inputs   \n",
    "\n",
    "args = RecipeNetArgs(dataset)\n",
    "args.num_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeVAE(nn.Module):\n",
    "  \n",
    "  def __init__(self, args) -> None:\n",
    "    super().__init__()\n",
    "    \n",
    "    hidden_size = args.hidden_size\n",
    "    z_size = args.z_size\n",
    "    activation_fn = args.activation_fn\n",
    "    gain = args.gain\n",
    "    \n",
    "    assert args.num_inputs >= 1\n",
    "    assert args.num_hidden_layers >= 1\n",
    "    assert hidden_size >= 1\n",
    "    assert z_size >= 1 and z_size < args.num_inputs\n",
    "\n",
    "    # Encoder and decoder networks\n",
    "    self.encoder = nn.Sequential()\n",
    "    self.encoder.append(layer_init_xavier(nn.Linear(args.num_inputs, hidden_size), gain))\n",
    "    self.encoder.append(activation_fn())\n",
    "    for _ in range(1, args.num_hidden_layers):\n",
    "      self.encoder.append(layer_init_xavier(nn.Linear(hidden_size, hidden_size), gain))\n",
    "      self.encoder.append(activation_fn())\n",
    "    self.encoder.append(layer_init_xavier(nn.Linear(hidden_size, z_size*2), gain))\n",
    "    self.encoder.append(activation_fn())\n",
    "    self.encoder.append(nn.BatchNorm1d(z_size*2))\n",
    "\n",
    "    self.decoder = nn.Sequential()\n",
    "    self.decoder.append(layer_init_xavier(nn.Linear(z_size, hidden_size)), gain)\n",
    "    self.decoder.append(activation_fn())\n",
    "    for _ in range(1, args.num_hidden_layers):\n",
    "      self.decoder.append(layer_init_xavier(nn.Linear(hidden_size, hidden_size), gain))\n",
    "      self.encoder.append(activation_fn())\n",
    "    self.decoder.append(layer_init_xavier(nn.Linear(hidden_size, args.num_inputs), gain))\n",
    "    \n",
    "    # Embeddings (NOTE: Any categoricals that don't have embeddings will be one-hot encoded)\n",
    "    self.grain_type_embedding         = nn.Embedding(args.num_grain_types, args.grain_type_embed_size)\n",
    "    self.adjunct_type_embedding       = nn.Embedding(args.num_adjunct_types, args.adjunct_type_embed_size) \n",
    "    self.hop_type_embedding           = nn.Embedding(args.num_hop_types, args.hop_type_embed_size)\n",
    "    self.misc_type_embedding          = nn.Embedding(args.num_misc_types, args.misc_type_embed_size)\n",
    "    self.microorganism_type_embedding = nn.Embedding(args.num_microorganism_types, args.microorganism_type_embed_size)\n",
    "    \n",
    "    # Post-network decoders (these are basically learned inverse embeddings)\n",
    "    self.grain_type_decoder         = layer_init_xavier(nn.Linear(args.grain_type_embed_size, args.num_grain_types), gain)\n",
    "    self.adjunct_type_decoder       = layer_init_xavier(nn.Linear(args.adjunct_type_embed_size, args.num_adjunct_types), gain)\n",
    "    self.hop_type_decoder           = layer_init_xavier(nn.Linear(args.hop_type_embed_size, args.num_hop_types), gain)\n",
    "    self.misc_type_decoder          = layer_init_xavier(nn.Linear(args.misc_type_embed_size, args.num_misc_types), gain)\n",
    "    self.microorganism_type_decoder = layer_init_xavier(nn.Linear(args.microorganism_type_embed_size, args.num_microorganism_types), gain)\n",
    "    \n",
    "    self.num_mash_step_types  = args.num_mash_step_types\n",
    "    self.num_hop_stage_types  = args.num_hop_stage_types\n",
    "    self.num_misc_stage_types = args.num_misc_stage_types\n",
    "    self.num_mo_stage_types   = args.num_mo_stage_types\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # Simple top-level heads (high-level recipe parameters)\n",
    "    x_simple_toplvl = torch.cat((x['boil_time'].unsqueeze(1), x['mash_ph'].unsqueeze(1), x['sparge_temp'].unsqueeze(1)), dim=1)\n",
    "    \n",
    "    # Mash step heads\n",
    "    # NOTE: Data shape is (B, S=number_of_mash_step_slots) for the\n",
    "    # following recipe tensors: {'mash_step_type_inds', 'mash_step_times', 'mash_step_avg_temps'}\n",
    "    mash_step_type_onehot = F.one_hot(x['mash_step_type_inds'].long(), self.num_mash_step_types)                        # (B, S, num_mash_step_types)\n",
    "    x_mash_steps = torch.cat((mash_step_type_onehot.flatten(1), x['mash_step_times'], x['mash_step_avg_temps']), dim=1) # (B, num_mash_step_types*S+S+S)\n",
    "    \n",
    "    # Ferment stage heads\n",
    "    # NOTE: Data shape is (B, S=2) for the following recipe tensors: {'ferment_stage_times', 'ferment_stage_temps'}\n",
    "    x_ferment_stages = torch.cat((x['ferment_stage_times'], x['ferment_stage_temps']), dim=1) # (B, 4=(S+S))\n",
    "\n",
    "    # Grain (malt bill) heads\n",
    "    # NOTE: Data shape is (B, S=num_grain_slots) for the following recipe tensors: {'grain_core_type_inds', 'grain_amts'}\n",
    "    grain_type_embed = self.grain_type_embedding(x['grain_core_type_inds'])     # (B, S, grain_type_embed_size)\n",
    "    x_grains = torch.cat((grain_type_embed.flatten(1), x['grain_amts']), dim=1) # (B, S*grain_type_embed_size+S)\n",
    "    \n",
    "    # Adjunct heads\n",
    "    # NOTE: Data shape is (B, S=num_adjunct_slots) for the following recipe tensors: {'adjunct_core_type_inds', 'adjunct_amts'}\n",
    "    adjunct_type_embed = self.adjunct_type_embedding(x['adjunct_core_type_inds']) # (B, S, adjunct_type_embed_size)\n",
    "    x_adjuncts = torch.cat((adjunct_type_embed.flatten(1), x['adjunct_amts']), dim=1)\n",
    "    \n",
    "    # Hop heads\n",
    "    # NOTE: Data shape is (B, S=num_hop_slots) for the following recipe tensors: \n",
    "    # {'hop_type_inds', 'hop_stage_type_inds', 'hop_times', 'hop_concentrations'}\n",
    "    hop_type_embed = self.hop_type_embedding(x['hop_type_inds']) # (B, S, hop_type_embed_size)\n",
    "    hop_stage_type_onehot = F.one_hot(x['hop_stage_type_inds'].long, self.num_hop_stage_types) # (B, S, num_hop_stage_types)\n",
    "    x_hops = torch.cat((hop_type_embed.flatten(1), hop_stage_type_onehot.flatten(1), x['hop_times'], x['hop_concentrations']), dim=1)\n",
    "    \n",
    "    # Misc. heads\n",
    "    # NOTE: Data shape is (B, S=num_misc_slots) for the following recipe tensors:\n",
    "    # {'misc_type_inds', 'misc_stage_inds', 'misc_times', 'misc_amts'}\n",
    "    misc_type_embed = self.misc_type_embedding(x['misc_type_inds'])                     # (B, S, misc_type_embed_size)\n",
    "    misc_stage_type_onehot = F.one_hot(x['misc_stage_inds'], self.num_misc_stage_types) # (B, S, num_misc_stage_types)\n",
    "    x_miscs = torch.cat((misc_type_embed.flatten(1), misc_stage_type_onehot.flatten(1), x['misc_times'], x['misc_amts']), dim=1)\n",
    "    \n",
    "    # Microorganism heads\n",
    "    # NOTE: Data shape is (B, S=num_microorganism_slots) for the following recipe tensors:\n",
    "    # {'mo_type_inds', 'mo_stage_inds'}\n",
    "    mo_type_embed = self.microorganism_type_embedding(x['mo_type_inds'])     # (B, S, microorganism_type_embed_size)\n",
    "    mo_stage_onehot = F.one_hot(x['mo_stage_inds'], self.num_mo_stage_types) # (B, S, num_mo_stage_types)\n",
    "    x_microorganisms = torch.cat((mo_type_embed.flatten(1), mo_stage_onehot.flatten(1)), dim=1)\n",
    "    \n",
    "    # Put all the recipe data together into a flattened tensor\n",
    "    x = torch.cat((x_simple_toplvl, x_mash_steps, x_ferment_stages, x_grains, x_adjuncts, x_hops, x_miscs, x_microorganisms), dim=1) # (B, num_inputs)\n",
    "    \n",
    "    # Encode\n",
    "    mean, logvar = torch.chunk(self.encoder(x), 2, dim=-1)\n",
    "    \n",
    "    # Decode\n",
    "    # TODO\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('brewbrain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf149ef9249c8031bd8b677d42c7b958c45095f85a0c42a709c15a6e71aa8835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
